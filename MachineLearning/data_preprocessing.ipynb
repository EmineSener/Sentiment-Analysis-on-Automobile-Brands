{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42630ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\emine\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\emine\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "from snowballstemmer import TurkishStemmer\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdb00a6",
   "metadata": {},
   "source": [
    "## Read data from source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d18ef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_path(sub_directory,file_name):\n",
    "    base_dir = os.getcwd()\n",
    "    target_dir = os.path.dirname(base_dir)\n",
    "    file_path = os.path.join(target_dir, sub_directory,file_name)\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b47b469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(sub_directory,file_name):\n",
    "    file_path = get_dataset_path(sub_directory,file_name)\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0853d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_lowercase(df):\n",
    "    return df[\"review\"].apply(lambda x:\" \".join(x.lower() for x in x.split()))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cd8b1d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m convert_to_lowercase(df)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df[\"review\"] = convert_to_lowercase(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fb5856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rare_words(df, threshold):\n",
    "    words = pd.Series(\" \".join(df[\"review\"]).split()).value_counts()\n",
    "    rare_words = words[words <= threshold].index.tolist()\n",
    "    return df[\"review\"].apply(lambda x:\" \".join(x for x in x.split() if x not in rare_words)) \n",
    " "
   ]
  },
  {
   "cell_type": "raw",
   "id": "efc17373",
   "metadata": {},
   "source": [
    "rare_words = remove_rare_words(df,threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f40df06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(df):\n",
    "    return df[\"review\"].apply(lambda x : re.sub(r'[^\\w\\s]', '',x))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6814bb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(df):\n",
    "    return df[\"review\"].apply(lambda x : re.sub(r\"http\\S+\", \"\",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef69961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_review(df):\n",
    "    print('REMOVING DUPLICATE REVIEW....')\n",
    "    return  df.drop_duplicates(subset = [\"review\"] ,keep='first', inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6d7df0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_quote(df):\n",
    "    for index, row in df.iterrows():\n",
    "        comment = row['review']\n",
    "        cleaned_comment = re.sub(r'quoteOrjinalden alıntı\\s+\\w+', '', comment)\n",
    "        df.at[index, 'review'] = cleaned_comment.strip()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b0c6bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(df):\n",
    "    return df[\"review\"].apply(lambda x : re.sub(\"\\S*\\d\\S*\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f713e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(df):\n",
    "    return df[\"review\"].apply(lambda x : re.sub('[^A-Za-z0-9]+', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96068721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_reviews(df):\n",
    "    return df['review'].apply(lambda text: word_tokenize(text, language='turkish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc208540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(df):\n",
    "    sw = set(stopwords.words(\"turkish\"))\n",
    "#     return df[\"review\"].apply(lambda tokens: [token for token in tokens if token not in sw])\n",
    "    return df[\"review\"].apply(lambda x:\" \".join(x for x in x.split() if x not in sw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17e37087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_stopwords2(df):\n",
    "#     sw = set(stopwords.words(\"turkish\"))\n",
    "#     return df[\"review\"].apply(lambda tokens: print(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef8a5ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(df):\n",
    "    turkStem = TurkishStemmer()\n",
    "    lemmatized_reviews = []\n",
    "    for review in tqdm(df['review'].values):\n",
    "        review = ' '.join(turkStem.stemWord(word) for word in review.split())\n",
    "        lemmatized_reviews.append(review.strip())\n",
    "    data['review']=lemmatized_reviews\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51242bf9",
   "metadata": {},
   "source": [
    "## Read data from source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c885512f",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "43cfdd3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bayiler satar artık 1.200 000 e burası türkiye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Siz bu fiyatlara 200 bin ekleyin. Bayide bulam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bu motor bu kasaya daha çok yakışmış          ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>850Bin TL eksik aracı almam için. Neyse 1 sene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eskiden milyoner olmak vardı derlerdi. Nerden ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  Bayiler satar artık 1.200 000 e burası türkiye...\n",
       "1  Siz bu fiyatlara 200 bin ekleyin. Bayide bulam...\n",
       "2  Bu motor bu kasaya daha çok yakışmış          ...\n",
       "3  850Bin TL eksik aracı almam için. Neyse 1 sene...\n",
       "4  Eskiden milyoner olmak vardı derlerdi. Nerden ..."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_data(\"WebScraping/Dataset\",\"dataset.csv\")\n",
    "df_copy=df.copy(deep=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d16cda2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 93991 entries, 0 to 93990\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   review  93991 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 734.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "37c60ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----SHAPE OF THE DATASET-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(93991, 1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('-----SHAPE OF THE DATASET-----')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2baa88",
   "metadata": {},
   "source": [
    "## Brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e17eb0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = get_dataset_path(\"WebScraping\",\"Brands\")\n",
    "file_list = os.listdir(file_path)\n",
    "\n",
    "brands = {}\n",
    "\n",
    "for file in file_list:\n",
    "     if file.endswith('.csv'):\n",
    "        df_path = os.path.join(file_path, file)\n",
    "        df_brand = pd.read_csv(df_path)\n",
    "        brands[file[:-4]] = df_brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d29b2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Clio ile rekabet etmesi zor görünüyor         ...</td>\n",
       "      <td>6 gün</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Önü ve arkası bambaşka tellerden çalıyor. Maky...</td>\n",
       "      <td>6 gün</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bu elektrikli araçlara Menzil tarikatının birş...</td>\n",
       "      <td>6 gün</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ön farları mahvetmişler. Önceki hali çok daha ...</td>\n",
       "      <td>6 gün</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>208 ne zaman gelecek acaba.  100 kw kötü olmuş...</td>\n",
       "      <td>6 gün</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review   date\n",
       "0  Clio ile rekabet etmesi zor görünüyor         ...  6 gün\n",
       "1  Önü ve arkası bambaşka tellerden çalıyor. Maky...  6 gün\n",
       "2  Bu elektrikli araçlara Menzil tarikatının birş...  6 gün\n",
       "3  Ön farları mahvetmişler. Önceki hali çok daha ...  6 gün\n",
       "4  208 ne zaman gelecek acaba.  100 kw kötü olmuş...  6 gün"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brands[\"Opel\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520d6af5",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1be361ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 0 NaN/Null values in dataset \n",
      "Number of duplicate in  dataset : 2661 \n"
     ]
    }
   ],
   "source": [
    "print(\"We have {} NaN/Null values in dataset \".format(df.isnull().values.sum()))\n",
    "print(\"Number of duplicate in  dataset : {} \".format(sum(df['review'].duplicated())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "52dc8e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "siz bu fiyatlara 200 bin ekleyin. bayide bulamayacaksınız, galeri de üstüne karını koyup satacak. yeni düzen böyle.\n",
      "şükredin. elhamdulillah 🙏\n",
      "hyundai̇ fi̇yat li̇stesi̇< resime gitmek için tıklayın >sağ üstte azami /maksimum satış fiyatları yazıyor.< resime gitmek için tıklayın >\n",
      "quote:orjinalden alıntı: hasanyy ben renault yetkili servis çalışanıyım.! 6 ay önce scenıc ıı aldım ve yıllık izne çıktım. samsun' dan fethiye ye gittim. tek şöför inanın hiç yorulmadım! çok sessiz ve rahat bir araç !! yüksek bir araç olduğu için içinde sıkışık ve basık hissi duymuyorsunuz. aile arabası diyorlar, evet ama biz iki kişiyiz uzun yol konforu için scenic ii aracını tercih ettim. kesinlikle öneririm. !!! araç jip gibi duruyor ama vergisi standart sade bir araç gibi alın başka araç kullandığınızda hemen inmek isteyeceksiniz katiliyorum, scenic ile ilgilenmeden once focus ya da c-max dusunuyordum. ne zaman ki scenic'in icine oturdum, digerleri bana oyuncak araba gibi geldi :)\n",
      "mercedes-benz birkaç gün önce e-serisi sedanlar için yeni bilgi-eğlence sistemini üç bölmeli dev ekran panellerle birlikte güncellemişti. mercedes şimdi ise cisco ile ortaklığa gideren webex toplantılarını otomobillerine getiriyor.mercedes-benz e-serisi ile toplantılara katılabilirsiniz2024 mercedes-benz e-serisi, wi-fi ve hücresel veri bağlantısı ile donatılacak, yani sürücüler webex uygulamasını cep telefonuna ihtiyaç duymadan doğrudan aracın bilgi-eğlence sisteminin dokunmatik ekranında görünecek şekilde indirebilecek. güvenlik açısından araç hareket halindeyken sadece sesli bağlantıya izin verilecek ancak park haline geçildiğinde görüntülü toplantılar, içerik paylaşımı gibi özellikler de kullanılabilir olacak.mobil dünya kongresi (mwc) kapsamında duyurulan bu ortaklık sayesinde yeni e-serisi otomobiller mobil ofis alanlarına dönüşecek gibi görünüyor. mercedes araçlarda üstün bir gürültü engelleme özelliğinin de olacağını söylerken bazı kullanım senaryoları da paylaştı. mercedes’e göre özellikle mimarlar çalışma sahasından ayrıldıktan sonra meslektaşları ile bu sayede anlık görüşmeler yapabilir.ayrıca bkz.mercedes, araçlarına tiktok’u entegre eden ilk otomobil üreticisi olduöte yandan bu, bir toplantı uygulamasının otomobillere ilk gelişi değil. webex halihazırda zaten bazı ford modellerde mevcut durumda. ek olarak zoom, araçlarından toplantılara katılmak isteyenler için tesla ile de anlaşmıştı. cisco ise bu hafta düzenlenen mwc kapsamında başka ortaklıklar da duyurmayı planlıyor. bu ortaklıklar arasında samsung’un amiral gemisi telefonlarında webex entegrasyonu ve intel ile 5g özelinde ortaklık planları bulunuyor.kaynak:https://www.engadget.com/mercedes-benz-is-bringing-webex-meetings-to-the-new-e-class-sedans-050009834.htmlkaynak:https://www.reuters.com/technology/cisco-works-with-mercedes-benz-create-mobile-office-2023-02-27/\n"
     ]
    }
   ],
   "source": [
    "# random reviews\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df[\"review\"].values[1])\n",
    "print(df[\"review\"].values[41])\n",
    "print(df[\"review\"].values[44])\n",
    "print(df[\"review\"].values[52])\n",
    "print(df[\"review\"].values[48])\n",
    "pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8f4ea333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO\n",
    "# remove duplicate review  ->OK\n",
    "# remove punctuations      ->OK\n",
    "# remove tags              ->OK   \n",
    "# remove quote             ->OK\n",
    "# remove numbers           ->OK\n",
    "# remove urls              ->OK\n",
    "# remove special characters->OK\n",
    "# convert lowercase        ->OK\n",
    "# remove rare words        ->çok yavaş çalışıyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "29b7b8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of review in  dataset : (93991, 1) \n",
      "REMOVING DUPLICATE REVIEW....\n",
      "Number of review in  dataset : (91105, 1) \n"
     ]
    }
   ],
   "source": [
    "print(\"Number of review in  dataset : {} \".format(df.shape))\n",
    "df = remove_duplicate_review(df)\n",
    "print(\"Number of review in  dataset : {} \".format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f6ca77ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bayiler satar artık 1200 000 e burası türkiye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>siz bu fiyatlara 200 bin ekleyin bayide bulama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bu motor bu kasaya daha çok yakışmış</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>850bin tl eksik aracı almam için neyse 1 sene ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eskiden milyoner olmak vardı derlerdi nerden n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0      bayiler satar artık 1200 000 e burası türkiye\n",
       "1  siz bu fiyatlara 200 bin ekleyin bayide bulama...\n",
       "2               bu motor bu kasaya daha çok yakışmış\n",
       "3  850bin tl eksik aracı almam için neyse 1 sene ...\n",
       "4  eskiden milyoner olmak vardı derlerdi nerden n..."
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"review\"] = remove_punctuation(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "8382f1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyundai fiyat listesi resime gitmek için tıklayın sağ üstte azami maksimum satış fiyatları yazıyor resime gitmek için tıklayın \n"
     ]
    }
   ],
   "source": [
    "print(df[\"review\"].values[44])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "746e9097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rare_words = remove_rare_words(df,threshold)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "5790a4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mercedesbenz birkaç gün önce eserisi sedanlar için yeni bilgieğlence sistemini üç bölmeli dev ekran panellerle birlikte güncellemişti mercedes şimdi ise cisco ile ortaklığa gideren webex toplantılarını otomobillerine getiriyormercedesbenz eserisi ile toplantılara katılabilirsiniz2024 mercedesbenz eserisi wifi ve hücresel veri bağlantısı ile donatılacak yani sürücüler webex uygulamasını cep telefonuna ihtiyaç duymadan doğrudan aracın bilgieğlence sisteminin dokunmatik ekranında görünecek şekilde indirebilecek güvenlik açısından araç hareket halindeyken sadece sesli bağlantıya izin verilecek ancak park haline geçildiğinde görüntülü toplantılar içerik paylaşımı gibi özellikler de kullanılabilir olacakmobil dünya kongresi mwc kapsamında duyurulan bu ortaklık sayesinde yeni eserisi otomobiller mobil ofis alanlarına dönüşecek gibi görünüyor mercedes araçlarda üstün bir gürültü engelleme özelliğinin de olacağını söylerken bazı kullanım senaryoları da paylaştı mercedese göre özellikle mimarlar çalışma sahasından ayrıldıktan sonra meslektaşları ile bu sayede anlık görüşmeler yapabilirayrıca bkzmercedes araçlarına tiktoku entegre eden ilk otomobil üreticisi olduöte yandan bu bir toplantı uygulamasının otomobillere ilk gelişi değil webex halihazırda zaten bazı ford modellerde mevcut durumda ek olarak zoom araçlarından toplantılara katılmak isteyenler için tesla ile de anlaşmıştı cisco ise bu hafta düzenlenen mwc kapsamında başka ortaklıklar da duyurmayı planlıyor bu ortaklıklar arasında samsungun amiral gemisi telefonlarında webex entegrasyonu ve intel ile 5g özelinde ortaklık planları bulunuyorkaynak\n"
     ]
    }
   ],
   "source": [
    "df[\"review\"] = remove_urls(df)\n",
    "print(df[\"review\"].values[48])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "aea0d2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quoteorjinalden alıntı hasanyy ben renault yetkili servis çalışanıyım 6 ay önce scenıc ıı aldım ve yıllık izne çıktım samsun dan fethiye ye gittim tek şöför inanın hiç yorulmadım çok sessiz ve rahat bir araç  yüksek bir araç olduğu için içinde sıkışık ve basık hissi duymuyorsunuz aile arabası diyorlar evet ama biz iki kişiyiz uzun yol konforu için scenic ii aracını tercih ettim kesinlikle öneririm  araç jip gibi duruyor ama vergisi standart sade bir araç gibi alın başka araç kullandığınızda hemen inmek isteyeceksiniz katiliyorum scenic ile ilgilenmeden once focus ya da cmax dusunuyordum ne zaman ki scenicin icine oturdum digerleri bana oyuncak araba gibi geldi \n"
     ]
    }
   ],
   "source": [
    "print(df[\"review\"].values[52])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "3e6f38c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quoteorjinalden alıntı hasanyy ben renault yetkili servis çalışanıyım 6 ay önce scenıc ıı aldım ve yıllık izne çıktım samsun dan fethiye ye gittim tek şöför inanın hiç yorulmadım çok sessiz ve rahat bir araç  yüksek bir araç olduğu için içinde sıkışık ve basık hissi duymuyorsunuz aile arabası diyorlar evet ama biz iki kişiyiz uzun yol konforu için scenic ii aracını tercih ettim kesinlikle öneririm  araç jip gibi duruyor ama vergisi standart sade bir araç gibi alın başka araç kullandığınızda hemen inmek isteyeceksiniz katiliyorum scenic ile ilgilenmeden once focus ya da cmax dusunuyordum ne zaman ki scenicin icine oturdum digerleri bana oyuncak araba gibi geldi\n"
     ]
    }
   ],
   "source": [
    "df = remove_quote(df)\n",
    "print(df[\"review\"].values[52])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c2f99b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bayiler satar artık   e burası türkiye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>siz bu fiyatlara  bin ekleyin bayide bulamayac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bu motor bu kasaya daha çok yakışmış</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tl eksik aracı almam için neyse  sene bekleye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eskiden milyoner olmak vardı derlerdi nerden n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0             bayiler satar artık   e burası türkiye\n",
       "1  siz bu fiyatlara  bin ekleyin bayide bulamayac...\n",
       "2               bu motor bu kasaya daha çok yakışmış\n",
       "3   tl eksik aracı almam için neyse  sene bekleye...\n",
       "4  eskiden milyoner olmak vardı derlerdi nerden n..."
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"review\"] = remove_numbers(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "034fa1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"review\"] = remove_special_characters(df)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "305b5011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bayiler satar artık e burası türkiye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fiyatlara bin ekleyin bayide bulamayacaksınız ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>motor kasaya yakışmış</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tl eksik aracı almam neyse sene bekleyem alırım</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eskiden milyoner olmak vardı derlerdi nerden g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0               bayiler satar artık e burası türkiye\n",
       "1  fiyatlara bin ekleyin bayide bulamayacaksınız ...\n",
       "2                              motor kasaya yakışmış\n",
       "3    tl eksik aracı almam neyse sene bekleyem alırım\n",
       "4  eskiden milyoner olmak vardı derlerdi nerden g..."
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"review\"] = remove_stopwords(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a12cacfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bayiler satar artık 1.200 000 e burası türkiye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Siz bu fiyatlara 200 bin ekleyin. Bayide bulam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bu motor bu kasaya daha çok yakışmış          ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>850Bin TL eksik aracı almam için. Neyse 1 sene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eskiden milyoner olmak vardı derlerdi. Nerden ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  Bayiler satar artık 1.200 000 e burası türkiye...\n",
       "1  Siz bu fiyatlara 200 bin ekleyin. Bayide bulam...\n",
       "2  Bu motor bu kasaya daha çok yakışmış          ...\n",
       "3  850Bin TL eksik aracı almam için. Neyse 1 sene...\n",
       "4  Eskiden milyoner olmak vardı derlerdi. Nerden ..."
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "7bce3719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bayi satar ar e buras türki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fiyat bin ekley bayi bulamayacak ga üst kar ko...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>motor kasa yakış</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tl eksik araç alma ne se bekleye alır</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eski milyoner olmak var der ner gel bir ülke p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0                        bayi satar ar e buras türki\n",
       "1  fiyat bin ekley bayi bulamayacak ga üst kar ko...\n",
       "2                                   motor kasa yakış\n",
       "3              tl eksik araç alma ne se bekleye alır\n",
       "4  eski milyoner olmak var der ner gel bir ülke p..."
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"review\"] = lemmatize(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d49b0bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bayi satar ar e buras türki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fiyat bin ekley bayi bulamayacak ga üst kar ko...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>motor kasa yakış</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tl eksik araç alma ne se bekleye alır</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eski milyoner olmak var der ner gel bir ülke p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>arkadaş eytli arabas deyip takıldık corolla ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>eski türkiye bayi git mi araç satmak bayi tak ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fiyat listes yer stok listes paylaşıl faydal h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>yok sen on gecicentoyota site gordugu fiya ali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alinmaz araba fiyat kadar zam gelecek sekil insaf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0                        bayi satar ar e buras türki\n",
       "1  fiyat bin ekley bayi bulamayacak ga üst kar ko...\n",
       "2                                   motor kasa yakış\n",
       "3              tl eksik araç alma ne se bekleye alır\n",
       "4  eski milyoner olmak var der ner gel bir ülke p...\n",
       "5  arkadaş eytli arabas deyip takıldık corolla ge...\n",
       "6  eski türkiye bayi git mi araç satmak bayi tak ...\n",
       "7  fiyat listes yer stok listes paylaşıl faydal h...\n",
       "8  yok sen on gecicentoyota site gordugu fiya ali...\n",
       "9  alinmaz araba fiyat kadar zam gelecek sekil insaf"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2b502b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bayiler satar artık 1.200 000 e burası türkiye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Siz bu fiyatlara 200 bin ekleyin. Bayide bulam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bu motor bu kasaya daha çok yakışmış          ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>850Bin TL eksik aracı almam için. Neyse 1 sene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eskiden milyoner olmak vardı derlerdi. Nerden ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Arkadaşlarla EYT'li arabası deyip takıldığımız...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Eski türkiyede bayiye gittin mi araç satmak iç...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fiyat listesi yerine stok listesi paylaşılsa d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Yok ya sen onu gecicenToyotanin sitesinde gord...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alinmaz bu arabalar bu fiyatlara, daha ne kada...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  Bayiler satar artık 1.200 000 e burası türkiye...\n",
       "1  Siz bu fiyatlara 200 bin ekleyin. Bayide bulam...\n",
       "2  Bu motor bu kasaya daha çok yakışmış          ...\n",
       "3  850Bin TL eksik aracı almam için. Neyse 1 sene...\n",
       "4  Eskiden milyoner olmak vardı derlerdi. Nerden ...\n",
       "5  Arkadaşlarla EYT'li arabası deyip takıldığımız...\n",
       "6  Eski türkiyede bayiye gittin mi araç satmak iç...\n",
       "7  Fiyat listesi yerine stok listesi paylaşılsa d...\n",
       "8  Yok ya sen onu gecicenToyotanin sitesinde gord...\n",
       "9  Alinmaz bu arabalar bu fiyatlara, daha ne kada..."
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a835244c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenize_reviews' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tokenize_reviews(df)\n\u001b[0;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenize_reviews' is not defined"
     ]
    }
   ],
   "source": [
    "df[\"review\"] = tokenize_reviews(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6e5039d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing1(df):\n",
    "    print(\"Number of review in  dataset : {} \".format(df.shape))\n",
    "    df = remove_duplicate_review(df)\n",
    "    print(\"Number of review in  dataset : {} \".format(df.shape))\n",
    "    print(\"hello\")\n",
    "    df[\"review\"] = remove_punctuation(df)\n",
    "    print(\"hello\")\n",
    "    df[\"review\"] = remove_urls(df)\n",
    "    print(\"hello\")\n",
    "    df = remove_quote(df)\n",
    "    print(\"hello\")\n",
    "    df[\"review\"] = remove_numbers(df)\n",
    "    print(\"hello\")\n",
    "    df[\"review\"] = convert_to_lowercase(df)\n",
    "    print(\"hello\")\n",
    "    df[\"review\"] = remove_stopwords(df)\n",
    "    print(\"hello\")\n",
    "#     df[\"review\"] = lemmatize(df)\n",
    "#     df[\"review\"] = tokenize_reviews(df)\n",
    "    print(\"hello\")\n",
    "    df.to_csv('preprocessing_dataset.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ee9474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    preprocessed_reviews = []\n",
    "    sw = set(stopwords.words(\"turkish\"))\n",
    "    for review in tqdm(df['review'].values):\n",
    "        review = re.sub(r'[^\\w\\s]', '', review)\n",
    "        review = re.sub(r'http\\S+', '', review)\n",
    "        review = re.sub(r'quoteOrjinalden alıntı\\s+\\w+', '', review)\n",
    "        review = re.sub(r'\\S*\\d\\S*', '', review)\n",
    "        review = re.sub(r'\\S*\\d\\S*', '', review)\n",
    "        review = ' '.join(word.lower() for word in review.split() if word.lower() not in sw)\n",
    "        preprocessed_reviews.append(review.strip())\n",
    "    df['review']=preprocessed_reviews\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d4f2925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_convert(df):\n",
    "    converted_dates = []\n",
    "    for date in tqdm(df['date'].values):\n",
    "        \n",
    "        if len(date.split()) >= 2:\n",
    "            num, unit = date.split()[0], date.split()[1]\n",
    "            if num == \"geçen\":\n",
    "                num = 1\n",
    "\n",
    "            if unit == \"gün\":\n",
    "                time = (datetime.now() - timedelta(days=int(num))).strftime('%d.%m.%Y')\n",
    "            elif unit ==\"hafta\":\n",
    "                time = (datetime.now() - timedelta(weeks=int(num))).strftime('%d.%m.%Y')\n",
    "            elif unit ==\"ay\":\n",
    "                time = (datetime.now() - timedelta(weeks=int(num))).strftime('%d.%m.%Y')\n",
    "#             az önce,... saat,... dk\n",
    "            else:\n",
    "                time = datetime.now().strftime('%d.%m.%Y')\n",
    "#         dün,şimdi,bugün\n",
    "        else:\n",
    "            if \"dün\" in date:\n",
    "                time = (datetime.now() - timedelta(days=1)).strftime('%d.%m.%Y')\n",
    "            elif \"şimdi\" in date or \"bugün\" in date:\n",
    "                time = datetime.now().strftime('%d.%m.%Y')              \n",
    "            else:\n",
    "                time = date\n",
    "        \n",
    "        converted_dates.append(time)\n",
    "    df['date']=converted_dates\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "49828489",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 93991/93991 [00:08<00:00, 10599.16it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_df = preprocessing(df)\n",
    "preprocessed_df.to_csv('preprocessed_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46a1e40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING DUPLICATE REVIEW....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 369/369 [00:00<00:00, 10504.19it/s]\n",
      "C:\\Users\\emine\\AppData\\Local\\Temp\\ipykernel_21920\\3736048588.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['review']=preprocessed_reviews\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 369/369 [00:00<00:00, 123342.22it/s]\n",
      "C:\\Users\\emine\\AppData\\Local\\Temp\\ipykernel_21920\\2096692961.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date']=converted_dates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING DUPLICATE REVIEW....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 957/957 [00:00<00:00, 15231.70it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 957/957 [00:00<00:00, 159157.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING DUPLICATE REVIEW....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 639/639 [00:00<00:00, 12744.58it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 639/639 [00:00<00:00, 128458.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING DUPLICATE REVIEW....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 20480.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING DUPLICATE REVIEW....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 2354/2354 [00:00<00:00, 15393.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2354/2354 [00:00<00:00, 147273.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING DUPLICATE REVIEW....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 268/268 [00:00<00:00, 17877.06it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 268/268 [00:00<00:00, 134410.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING DUPLICATE REVIEW....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 1793/1793 [00:00<00:00, 15909.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1793/1793 [00:00<00:00, 149859.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING DUPLICATE REVIEW....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 570/570 [00:00<00:00, 18416.62it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 570/570 [00:00<00:00, 141707.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING DUPLICATE REVIEW....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 395/395 [00:00<00:00, 15828.62it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 395/395 [00:00<00:00, 130699.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING DUPLICATE REVIEW....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 393/393 [00:00<00:00, 12301.21it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 393/393 [00:00<00:00, 130905.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING DUPLICATE REVIEW....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 850/850 [00:00<00:00, 14445.19it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 850/850 [00:00<00:00, 142463.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING DUPLICATE REVIEW....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 48/48 [00:00<00:00, 12030.27it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING DUPLICATE REVIEW....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 715/715 [00:00<00:00, 14338.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 715/715 [00:00<00:00, 119474.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING DUPLICATE REVIEW....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 91/91 [00:00<00:00, 13038.69it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 91/91 [00:00<00:00, 45617.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING DUPLICATE REVIEW....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 438/438 [00:00<00:00, 15128.55it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 438/438 [00:00<00:00, 146698.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING DUPLICATE REVIEW....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 139/139 [00:00<00:00, 15482.07it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 139/139 [00:00<00:00, 139275.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING DUPLICATE REVIEW....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 376/376 [00:00<00:00, 13948.12it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 376/376 [00:00<00:00, 125641.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING DUPLICATE REVIEW....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 410/410 [00:00<00:00, 9788.06it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 410/410 [00:00<00:00, 135364.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING DUPLICATE REVIEW....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 1785/1785 [00:00<00:00, 18164.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1785/1785 [00:00<00:00, 149151.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING DUPLICATE REVIEW....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 660/660 [00:00<00:00, 19445.49it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 660/660 [00:00<00:00, 132458.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING DUPLICATE REVIEW....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 1162/1162 [00:00<00:00, 11648.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1162/1162 [00:00<00:00, 116508.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING DUPLICATE REVIEW....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 249/249 [00:00<00:00, 10841.37it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 249/249 [00:00<00:00, 83191.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING DUPLICATE REVIEW....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<00:00, 7683.10it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 23/23 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING DUPLICATE REVIEW....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 331/331 [00:00<00:00, 11444.26it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 331/331 [00:00<00:00, 165867.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING DUPLICATE REVIEW....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 3540/3540 [00:00<00:00, 14557.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 3540/3540 [00:00<00:00, 147698.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING DUPLICATE REVIEW....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 111/111 [00:00<00:00, 9274.44it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 111/111 [00:00<00:00, 110586.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING DUPLICATE REVIEW....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 613/613 [00:00<00:00, 12547.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 613/613 [00:00<00:00, 123048.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING DUPLICATE REVIEW....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 115/115 [00:00<00:00, 9609.04it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 115/115 [00:00<00:00, 114462.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING DUPLICATE REVIEW....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 2341/2341 [00:00<00:00, 14140.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 2341/2341 [00:00<00:00, 138079.96it/s]\n"
     ]
    }
   ],
   "source": [
    "for name, df in brands.items():\n",
    "    df = remove_duplicate_review(df)\n",
    "    df = preprocessing(df)\n",
    "    brands[name] = df\n",
    "    df = time_convert(df)\n",
    "    \n",
    "    if not os.path.exists(\"Brands\"):\n",
    "        os.makedirs(\"Brands\")\n",
    "    df.to_csv(os.path.join(\"Brands\", f'{name}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d406cb3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clio rekabet etmesi zor görünüyor</td>\n",
       "      <td>02.10.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>önü arkası bambaşka tellerden çalıyor makyajsı...</td>\n",
       "      <td>02.10.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>elektrikli araçlara menzil tarikatının birşeyl...</td>\n",
       "      <td>02.10.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ön farları mahvetmişler önceki hali iyiydi</td>\n",
       "      <td>02.10.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zaman gelecek kw kötü olmuş kw varken</td>\n",
       "      <td>02.10.2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review        date\n",
       "0                  clio rekabet etmesi zor görünüyor  02.10.2023\n",
       "1  önü arkası bambaşka tellerden çalıyor makyajsı...  02.10.2023\n",
       "2  elektrikli araçlara menzil tarikatının birşeyl...  02.10.2023\n",
       "3         ön farları mahvetmişler önceki hali iyiydi  02.10.2023\n",
       "4              zaman gelecek kw kötü olmuş kw varken  02.10.2023"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brands[\"Opel\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "12a8880e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▊                                                                         | 4657/93991 [01:35<30:36, 48.63it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m lemmatize(df)\n",
      "Cell \u001b[1;32mIn[54], line 5\u001b[0m, in \u001b[0;36mlemmatize\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      3\u001b[0m lemmatized_reviews \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m review \u001b[38;5;129;01min\u001b[39;00m tqdm(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[1;32m----> 5\u001b[0m     review \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(turkStem\u001b[38;5;241m.\u001b[39mstemWord(word) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m review\u001b[38;5;241m.\u001b[39msplit())\n\u001b[0;32m      6\u001b[0m     lemmatized_reviews\u001b[38;5;241m.\u001b[39mappend(review\u001b[38;5;241m.\u001b[39mstrip())\n\u001b[0;32m      7\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mlemmatized_reviews\n",
      "Cell \u001b[1;32mIn[54], line 5\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m lemmatized_reviews \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m review \u001b[38;5;129;01min\u001b[39;00m tqdm(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[1;32m----> 5\u001b[0m     review \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(turkStem\u001b[38;5;241m.\u001b[39mstemWord(word) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m review\u001b[38;5;241m.\u001b[39msplit())\n\u001b[0;32m      6\u001b[0m     lemmatized_reviews\u001b[38;5;241m.\u001b[39mappend(review\u001b[38;5;241m.\u001b[39mstrip())\n\u001b[0;32m      7\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mlemmatized_reviews\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\snowballstemmer\\basestemmer.py:319\u001b[0m, in \u001b[0;36mBaseStemmer.stemWord\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstemWord\u001b[39m(\u001b[38;5;28mself\u001b[39m, word):\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_current(word)\n\u001b[1;32m--> 319\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stem()\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_current()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\snowballstemmer\\turkish_stemmer.py:1631\u001b[0m, in \u001b[0;36mTurkishStemmer._stem\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlimit\n\u001b[0;32m   1630\u001b[0m v_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlimit \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcursor\n\u001b[1;32m-> 1631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__r_stem_nominal_verb_suffixes()\n\u001b[0;32m   1632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlimit \u001b[38;5;241m-\u001b[39m v_1\n\u001b[0;32m   1633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mB_continue_stemming_noun_suffixes:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\snowballstemmer\\turkish_stemmer.py:789\u001b[0m, in \u001b[0;36mTurkishStemmer.__r_stem_nominal_verb_suffixes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m lab22: \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlimit \u001b[38;5;241m-\u001b[39m v_1\n\u001b[1;32m--> 789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__r_mark_DUr():\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbra \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcursor\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\snowballstemmer\\turkish_stemmer.py:581\u001b[0m, in \u001b[0;36mTurkishStemmer.__r_mark_DUr\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__r_check_vowel_harmony():\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_among_b(TurkishStemmer\u001b[38;5;241m.\u001b[39ma_18) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\snowballstemmer\\basestemmer.py:216\u001b[0m, in \u001b[0;36mBaseStemmer.find_among_b\u001b[1;34m(self, v)\u001b[0m\n\u001b[0;32m    214\u001b[0m common \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(common_i, common_j)\n\u001b[0;32m    215\u001b[0m w \u001b[38;5;241m=\u001b[39m v[k]\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(w\u001b[38;5;241m.\u001b[39ms) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m common, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;241m-\u001b[39m common \u001b[38;5;241m==\u001b[39m lb:\n\u001b[0;32m    218\u001b[0m         diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = lemmatize(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "86ae3d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bayiler satar artık e burası türkiye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fiyatlara bin ekleyin bayide bulamayacaksınız ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>motor kasaya yakışmış</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tl eksik aracı almam neyse sene bekleyem alırım</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eskiden milyoner olmak vardı derlerdi nerden g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0               bayiler satar artık e burası türkiye\n",
       "1  fiyatlara bin ekleyin bayide bulamayacaksınız ...\n",
       "2                              motor kasaya yakışmış\n",
       "3    tl eksik aracı almam neyse sene bekleyem alırım\n",
       "4  eskiden milyoner olmak vardı derlerdi nerden g..."
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dd5050",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
