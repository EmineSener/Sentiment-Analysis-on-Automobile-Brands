{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83f8f00f",
   "metadata": {},
   "source": [
    "## Create dataset with web scraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e1bac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec340e4",
   "metadata": {},
   "source": [
    "* certain pages in the forum have a significant amount of data, and there is a need to prevent the dataset from being dominated or overwhelmed by comments from a single source.`max_comment_pages` is for this.\n",
    "*  the website has two distinct structures: one for reviews related to all brands in general and another for reviews specific to a particular brand.Collect train and test data from a structure that includes comments for all brands,analysis data from a specific structure.Same comment can appear in both structures.Use a time limit to prevent for this.Analysis data consists of comments made in the last 6 months, while training data includes comments made more than 6 months ago.The `dataset_start_page` refers to the page containing comments made about 6 months ago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5631d2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://mini.donanimhaber.com/markalar--f338\"\n",
    "dataset_start_page = 140\n",
    "total_pages = 2700\n",
    "page_number = 1\n",
    "file = \"dataset.csv\"\n",
    "max_comments = 300000   \n",
    "max_comment_pages = 200  \n",
    "comment_number = 34395"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8727b214",
   "metadata": {},
   "source": [
    "For request cookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57d3fdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) \\\n",
    "     AppleWebKit/537.36 (KHTML, like Gecko) \\\n",
    "     Chrome/90.0.4430.212 Safari/537.36',\n",
    "    'Accept-Language': 'tr-TR,tr;q=0.9,en-US;q=0.8,en;q=0.7'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de51eff",
   "metadata": {},
   "source": [
    "Scrape the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2da0ea89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(url):\n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS)\n",
    "        if response.status_code == 200:\n",
    "            return response.text\n",
    "        else:\n",
    "            print(\"Request failed with status code:\", response.status_code)\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b9ee8f",
   "metadata": {},
   "source": [
    "Parse the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5f234da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_code(url, parser='html.parser'):\n",
    "    htmldata = get_data(url)\n",
    "    soup = BeautifulSoup(htmldata, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146903b5",
   "metadata": {},
   "source": [
    "Extract the title links from current page\n",
    "* The site's homepage contains links with comments. First, the links are parsed from the homepage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4520cf55",
   "metadata": {},
   "outputs": [],
   "source": [
    " def extract_links(current_page_url):\n",
    "    links = []\n",
    "    global page_number\n",
    "    soup = html_code(current_page_url)\n",
    "    topics = soup.find_all(name = \"dl\")\n",
    "    for topic in topics:\n",
    "        link = topic.find('a').get(\"href\")\n",
    "        if link:\n",
    "            links.append(link)\n",
    "    print(f\"page{page_number} completed\")\n",
    "    page_number += 1\n",
    "    return links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f682b9b5",
   "metadata": {},
   "source": [
    "The parsed links are further processed to access the comment pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "451c6c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_links(links):\n",
    "    cleaned_links = [f'https://mini.donanimhaber.com/{link}' for link in links if link.startswith('/')]\n",
    "#     current_comment_page_url = f'https://mini.donanimhaber.com/{current_comment_page_url}'\n",
    "    return cleaned_links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f5ace6",
   "metadata": {},
   "source": [
    "The website has a multi-page structure.Generate current page url from multipage structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7859011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_page_url(base_url, dataset_start_page, total_pages):\n",
    "    page_urls = []\n",
    "    for page_number in range(dataset_start_page,total_pages+1):\n",
    "#         print(page_number,\"...\")\n",
    "        page_url = f'{base_url}?sayfa={page_number}'\n",
    "        page_urls.append(page_url)\n",
    "    return page_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aa1196",
   "metadata": {},
   "source": [
    "Comment pages has a multi-page structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7f60cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_comment_page_url(current_comment_page_url):\n",
    "    comment_page_urls = []\n",
    "    soup = html_code(current_comment_page_url)\n",
    "    page_numbers = soup.find_all(\"option\")\n",
    "    \n",
    "    if page_numbers:  \n",
    "        page_number = int(page_numbers[-1][\"value\"])\n",
    "    else:\n",
    "        page_number = 1\n",
    "    if page_number > max_comment_pages:\n",
    "        page_number = max_comment_pages\n",
    "    for i in range(1, page_number+1):\n",
    "        comment_page_url = f'{current_comment_page_url}-{i}'\n",
    "        comment_page_urls.append(comment_page_url)\n",
    "    return comment_page_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cb6bc1",
   "metadata": {},
   "source": [
    "Extract the reviews to train and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "880a67c1",
   "metadata": {},
   "outputs": [],
   "source": [
    " def extract_comments(link):\n",
    "#     comment_page_url = f'https://mini.donanimhaber.com/{link}' \n",
    "\n",
    "    soup = html_code(link)\n",
    "    global comment_number\n",
    "    comments = []\n",
    "    comment_elements = soup.find_all(class_=\"comcom\")\n",
    "    for comment_element in comment_elements:\n",
    "        comment = comment_element.find(\"td\").getText()\n",
    "        if comment:\n",
    "            if not has_question_mark(comment):\n",
    "                comments.append(comment)\n",
    "                comment_number += 1\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88fa35a",
   "metadata": {},
   "source": [
    "Extract the reviews and their dates for analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "512a6cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_comments_to_time(link):\n",
    "    soup = html_code(link)\n",
    "    global comment_number\n",
    "    comments = []\n",
    "    times = []\n",
    "    comment_elements = soup.find_all(class_=\"comcom\")\n",
    "    dates = soup.find_all(class_ = \"date\")\n",
    "    dates = [date.get_text() for date in dates]\n",
    "    for index, comment_element in enumerate(comment_elements):\n",
    "        comment = comment_element.find(\"td\").getText()\n",
    "        time_passed = is_time_passed(dates[index])\n",
    "        if not time_passed and not has_question_mark(comment):\n",
    "            comments.append(comment)\n",
    "            times.append(dates[index].replace(\"\\n\",\"\"))\n",
    "            comment_number += 1\n",
    "    return comments,times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff960ef",
   "metadata": {},
   "source": [
    "We won't add reviews with question sentences to the dataset.Because they most likely won't determine sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2cd3426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_question_mark(text):\n",
    "    return \"?\" in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8cb6cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_comments(comments):\n",
    "    cleaned_comments = [comment.replace('\\r\\n', '') for comment in comments]\n",
    "    return cleaned_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefaa1eb",
   "metadata": {},
   "source": [
    "The analysis dataset and training dataset will be saved in different formats. Since we will do sentiment analysis according to time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a927c106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(data, file):\n",
    "    if isinstance(data, list):\n",
    "        df = pd.DataFrame({'review': data})\n",
    "        folder = \"Dataset\"\n",
    "    elif isinstance(data, tuple):\n",
    "        df = pd.DataFrame(data, columns=['review', 'date'])\n",
    "#         df = pd.DataFrame({'review': comments, 'date': dates})\n",
    "        folder = \"Brands\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid data format\")\n",
    "    \n",
    "    filepath = Path('/'.join([folder, file]))\n",
    "    filepath.parent.mkdir(parents=True, exist_ok=True) \n",
    "    \n",
    "    if os.path.isfile(filepath):\n",
    "        df.to_csv(filepath, mode='a', index=False, encoding='utf-8')\n",
    "    else:\n",
    "        df.to_csv(filepath, index=False, encoding='utf-8')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d04db83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "\n",
    "filepath = Path('dataset/out.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "# df.to_csv(filepath)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c40eb5",
   "metadata": {},
   "source": [
    "# Create Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8cb8d1",
   "metadata": {},
   "source": [
    "Collect reviews for the purpose of ML model training and testing, and we won't need dates or labels as part of the collected data. Collection of comments only, without dates or labels for model training and testing.\n",
    "There are no labels in the reviews on the site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1da44b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(base_url, dataset_start_page, total_pages ,file):\n",
    "    page_urls = generate_page_url(base_url, dataset_start_page, total_pages)\n",
    "    \n",
    "    for page_url in page_urls:\n",
    "        links = extract_links(page_url)\n",
    "        links = clean_links(links)\n",
    "        for link in links:\n",
    "            comment_links = generate_comment_page_url(link)\n",
    "            comment_links = clean_comments(comment_links)\n",
    "            for comment_link in comment_links:\n",
    "                comments = extract_comments(comment_link)\n",
    "                comments = clean_comments(comments)\n",
    "                save_to_csv(comments,file)\n",
    "        print(comment_number)\n",
    "        if comment_number > max_comments:\n",
    "            print(\"Dataset completed!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d760b7d",
   "metadata": {},
   "source": [
    "Collect reviews of car brands and their dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37d0196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_analyse_data(base_url):\n",
    "    brands = extract_brands(base_url)\n",
    "    \n",
    "    for brand in brands.keys():\n",
    "        \n",
    "        page_urls = generate_page_url_to_brand(brands[brand])\n",
    "        \n",
    "        for url in page_urls:\n",
    "            \n",
    "            links = extract_links_to_time(url)\n",
    "            \n",
    "            if not links:\n",
    "                break\n",
    "            else:\n",
    "                links = clean_links(links)\n",
    "                for link in links:\n",
    "                    comment_links = generate_comment_page_url(link)\n",
    "                    comment_links = clean_comments(comment_links)\n",
    "                    for comment_link in reversed(comment_links):\n",
    "                        comments,dates = extract_comments_to_time(comment_link)\n",
    "                        if not comments:\n",
    "                            break\n",
    "                        else:\n",
    "                            comments = clean_comments(comments)\n",
    "                            save_to_csv(tuple(zip(comments, dates)),f'{brand}.csv')\n",
    "        print(brand,\"dataset completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "feec556a",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_number = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8e3a05a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page2 completed\n",
      "page3 completed\n",
      "page4 completed\n",
      "page5 completed\n",
      "page6 completed\n",
      "page7 completed\n",
      "page8 completed\n",
      "Renault dataset completed\n",
      "page9 completed\n",
      "page10 completed\n",
      "page11 completed\n",
      "page12 completed\n",
      "page13 completed\n",
      "Opel dataset completed\n",
      "page14 completed\n",
      "page15 completed\n",
      "page16 completed\n",
      "page17 completed\n",
      "page18 completed\n",
      "Fiat dataset completed\n",
      "page19 completed\n",
      "page20 completed\n",
      "page21 completed\n",
      "page22 completed\n",
      "Honda dataset completed\n",
      "page23 completed\n",
      "page24 completed\n",
      "page25 completed\n",
      "page26 completed\n",
      "page27 completed\n",
      "Toyota dataset completed\n",
      "page28 completed\n",
      "page29 completed\n",
      "page30 completed\n",
      "page31 completed\n",
      "page32 completed\n",
      "page33 completed\n",
      "Citroen dataset completed\n",
      "page34 completed\n",
      "page35 completed\n",
      "page36 completed\n",
      "page37 completed\n",
      "page38 completed\n",
      "page39 completed\n",
      "page40 completed\n",
      "page41 completed\n",
      "Vw dataset completed\n",
      "page42 completed\n",
      "page43 completed\n",
      "page44 completed\n",
      "page45 completed\n",
      "page46 completed\n",
      "page47 completed\n",
      "Peugeot dataset completed\n",
      "page48 completed\n",
      "page49 completed\n",
      "page50 completed\n",
      "page51 completed\n",
      "page52 completed\n",
      "Hyundai dataset completed\n",
      "page53 completed\n",
      "page54 completed\n",
      "page55 completed\n",
      "page56 completed\n",
      "page57 completed\n",
      "Ford dataset completed\n",
      "page58 completed\n",
      "page59 completed\n",
      "page60 completed\n",
      "page61 completed\n",
      "page62 completed\n",
      "page63 completed\n",
      "page64 completed\n",
      "Bmw dataset completed\n",
      "page65 completed\n",
      "page66 completed\n",
      "page67 completed\n",
      "page68 completed\n",
      "page69 completed\n",
      "Mercedes dataset completed\n",
      "page70 completed\n",
      "page71 completed\n",
      "page72 completed\n",
      "page73 completed\n",
      "Audi dataset completed\n",
      "page74 completed\n",
      "page75 completed\n",
      "Mazda dataset completed\n",
      "page76 completed\n",
      "page77 completed\n",
      "page78 completed\n",
      "Kia dataset completed\n",
      "page79 completed\n",
      "page80 completed\n",
      "page81 completed\n",
      "Volvo dataset completed\n",
      "page82 completed\n",
      "page83 completed\n",
      "page84 completed\n",
      "Mitsubishi dataset completed\n",
      "page85 completed\n",
      "page86 completed\n",
      "Saab dataset completed\n",
      "page87 completed\n",
      "page88 completed\n",
      "page89 completed\n",
      "page90 completed\n",
      "Dacia dataset completed\n",
      "page91 completed\n",
      "page92 completed\n",
      "page93 completed\n",
      "page94 completed\n",
      "Skoda dataset completed\n",
      "page95 completed\n",
      "page96 completed\n",
      "page97 completed\n",
      "Nissan dataset completed\n",
      "page98 completed\n",
      "page99 completed\n",
      "page100 completed\n",
      "Seat dataset completed\n",
      "page101 completed\n",
      "page102 completed\n",
      "page103 completed\n",
      "Chevrolet dataset completed\n",
      "page104 completed\n",
      "page105 completed\n",
      "Alfa Romeo dataset completed\n",
      "page106 completed\n",
      "page107 completed\n",
      "Subaru dataset completed\n",
      "page108 completed\n",
      "page109 completed\n",
      "page110 completed\n",
      "Suzuki dataset completed\n",
      "page111 completed\n",
      "page112 completed\n",
      "Jeep dataset completed\n",
      "page113 completed\n",
      "page114 completed\n",
      "Tesla dataset completed\n",
      "page115 completed\n",
      "TOGG dataset completed\n",
      "page116 completed\n",
      "page117 completed\n",
      "page118 completed\n",
      "Diğer Markalar dataset completed\n"
     ]
    }
   ],
   "source": [
    "scrape_analyse_data(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd99a7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_dataset(base_url, dataset_start_page, total_pages ,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f0514c",
   "metadata": {},
   "source": [
    "53 sayfa + 87"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94871d61",
   "metadata": {},
   "source": [
    "Extract brand names and brand-specific forum links from the site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2e67293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_brands(base_url):\n",
    "    soup = html_code(base_url)\n",
    "    span_elements = soup.find_all('span', class_='subcat4')\n",
    "    brands = {}\n",
    "    for span in span_elements:\n",
    "        link_element = span.find('a')\n",
    "        if link_element:\n",
    "            brand_name = link_element.get_text()\n",
    "            brand_link = link_element['href']\n",
    "            brand_link = f'https://mini.donanimhaber.com{brand_link}'\n",
    "            brands[brand_name] = brand_link\n",
    "    return brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18914197",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands =extract_brands(\"https://mini.donanimhaber.com/markalar--f338\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bd95f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renault\n",
      "https://mini.donanimhaber.com/renault--f339\n",
      "Opel\n",
      "https://mini.donanimhaber.com/opel--f340\n",
      "Fiat\n",
      "https://mini.donanimhaber.com/fiat--f341\n",
      "Honda\n",
      "https://mini.donanimhaber.com/honda--f342\n",
      "Toyota\n",
      "https://mini.donanimhaber.com/toyota--f343\n",
      "Citroen\n",
      "https://mini.donanimhaber.com/citroen--f344\n",
      "Vw\n",
      "https://mini.donanimhaber.com/vw--f345\n",
      "Peugeot\n",
      "https://mini.donanimhaber.com/peugeot--f346\n",
      "Hyundai\n",
      "https://mini.donanimhaber.com/hyundai--f347\n",
      "Ford\n",
      "https://mini.donanimhaber.com/ford--f348\n",
      "Bmw\n",
      "https://mini.donanimhaber.com/bmw--f438\n",
      "Mercedes\n",
      "https://mini.donanimhaber.com/mercedes--f439\n",
      "Audi\n",
      "https://mini.donanimhaber.com/audi--f440\n",
      "Mazda\n",
      "https://mini.donanimhaber.com/mazda--f441\n",
      "Kia\n",
      "https://mini.donanimhaber.com/kia--f442\n",
      "Volvo\n",
      "https://mini.donanimhaber.com/volvo--f496\n",
      "Mitsubishi\n",
      "https://mini.donanimhaber.com/mitsubishi--f537\n",
      "Saab\n",
      "https://mini.donanimhaber.com/saab--f576\n",
      "Dacia\n",
      "https://mini.donanimhaber.com/dacia--f577\n",
      "Skoda\n",
      "https://mini.donanimhaber.com/skoda--f578\n",
      "Nissan\n",
      "https://mini.donanimhaber.com/nissan--f579\n",
      "Seat\n",
      "https://mini.donanimhaber.com/seat--f580\n",
      "Chevrolet\n",
      "https://mini.donanimhaber.com/chevrolet--f581\n",
      "Alfa Romeo\n",
      "https://mini.donanimhaber.com/alfa-romeo--f582\n",
      "Subaru\n",
      "https://mini.donanimhaber.com/subaru--f624\n",
      "Suzuki\n",
      "https://mini.donanimhaber.com/suzuki--f864\n",
      "Jeep\n",
      "https://mini.donanimhaber.com/jeep--f2130\n",
      "Tesla\n",
      "https://mini.donanimhaber.com/tesla--f2613\n",
      "TOGG\n",
      "https://mini.donanimhaber.com/togg--f2765\n",
      "Diğer Markalar\n",
      "https://mini.donanimhaber.com/diger-markalar--f349\n"
     ]
    }
   ],
   "source": [
    "for brand in brands.keys():\n",
    "    print(brand)\n",
    "    print(brands[brand])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f5f1e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_page_url_to_brand(brand_link):\n",
    "    page_urls = []\n",
    "    soup = html_code(brand_link)\n",
    "    \n",
    "    page_numbers = soup.find_all(\"option\")\n",
    "    \n",
    "    if page_numbers:  \n",
    "        page_number = int(page_numbers[-1][\"value\"])\n",
    "    else:\n",
    "        page_number = 1\n",
    "        \n",
    "    for i in range(1, page_number+1):\n",
    "        page_url = f'{brand_link}?sayfa={i}'\n",
    "        page_urls.append(page_url)\n",
    "    return page_urls\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85ca4bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=1',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=2',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=3',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=4',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=5',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=6',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=7',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=8',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=9',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=10',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=11',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=12',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=13',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=14',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=15',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=16',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=17',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=18',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=19',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=20',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=21',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=22',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=23',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=24',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=25',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=26',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=27',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=28',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=29',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=30',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=31',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=32',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=33',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=34',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=35',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=36',\n",
       " 'https://mini.donanimhaber.com/alfa-romeo--f582?sayfa=37']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_page_url_to_brand('https://mini.donanimhaber.com/alfa-romeo--f582')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7355214e",
   "metadata": {},
   "source": [
    "Comments from the last 11 months are used for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bcaf93b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_links_to_time(current_page_url):\n",
    "    links = []\n",
    "    global page_number\n",
    "    time_passed = False    \n",
    "    soup = html_code(current_page_url)\n",
    "    topics = soup.find_all('a', style=\"line-height: 16px;\")\n",
    "    times = soup.find_all('span', style='margin-bottom: 5px;')\n",
    "    for  topic in topics:\n",
    "        link = topic.get(\"href\")\n",
    "        time = times[topics.index(topic)].find(\"a\").getText()\n",
    "        if \",\" in time:\n",
    "            time = time.split(\",\")[1]\n",
    "            time_passed = is_time_passed(time)\n",
    "            if  not time_passed:\n",
    "                links.append(link)\n",
    "    print(f\"page{page_number} completed\")\n",
    "    page_number += 1\n",
    "    return links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc31838d",
   "metadata": {},
   "source": [
    "Control last 6 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e04a0d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_time_passed(time):\n",
    "    if len(time.split()) >= 2:\n",
    "        num, unit = time.split()[0], time.split()[1]\n",
    "        if unit == \"yıl\":\n",
    "            time_passed = True\n",
    "        elif num ==\"geçen\":\n",
    "            time_passed = False\n",
    "        elif unit ==\"ay\" and int(num) >= 11:\n",
    "            time_passed = True\n",
    "        else:\n",
    "            time_passed = False\n",
    "    else:\n",
    "        time_passed = False  \n",
    "    return time_passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72aef2ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page1 completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/u-y-a-r-i--128253373',\n",
       " '/renault-kardian-suv-un-tasarimina-iliskin-yeni-gorseller-paylasildi--157005303',\n",
       " '/2020-renault-clio-5-ana-konu--136922052',\n",
       " '/captur-2-2020--143329326',\n",
       " '/2016-renault-talisman-ana-konu--107705078',\n",
       " '/renault-larin-teyp-kodu-nasil-girilir--5913162',\n",
       " '/motor-takozu-degisti-rolantide-sarsinti-artti-bir-bilen--18387808',\n",
       " '/yeni-renault-kadjar-ana-konu--102295469',\n",
       " '/yeni-megane-e-tech-yuzde-100-elektrikli-van-da-duzenlenen-etkinlikle-tanitildi--156893544',\n",
       " '/yeni-renault-clio-turkiye-de-iste-fiyati-ve-ozellikleri--156892736',\n",
       " '/elektrikli-renault-zoe-ana-konu--155319687',\n",
       " '/laguna-ii-grubu-gelin-konusalim-tartisalim-paylasalim--35550700',\n",
       " '/renault-austral-e-tech-full-hybrid-turkiye-de-iste-fiyati-ve-ozellikleri--156559932',\n",
       " '/0-9-tce-symbol-benzinle-calismiyor--156267020',\n",
       " '/renault-latitude-kulubu--48906332',\n",
       " '/renault-fluence-1-5dci-ecu-arizasi--156828671']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_links_to_time(\"https://mini.donanimhaber.com/renault--f339?sayfa=1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
